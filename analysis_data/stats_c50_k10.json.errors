GPU 2: CUDA out of memory. Tried to allocate 1.44 GiB. GPU 2 has a total capacity of 79.11 GiB of which 760.94 MiB is free. Including non-PyTorch memory, this process has 78.36 GiB memory in use. Of the allocated memory 59.89 GiB is allocated by PyTorch, and 17.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 884.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 864.94 MiB is free. Including non-PyTorch memory, this process has 78.26 GiB memory in use. Of the allocated memory 62.89 GiB is allocated by PyTorch, and 14.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 868.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 334.94 MiB is free. Including non-PyTorch memory, this process has 78.77 GiB memory in use. Of the allocated memory 62.14 GiB is allocated by PyTorch, and 15.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 760.94 MiB is free. Including non-PyTorch memory, this process has 78.36 GiB memory in use. Of the allocated memory 54.05 GiB is allocated by PyTorch, and 23.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 55.95 GiB is allocated by PyTorch, and 21.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 796.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 57.60 GiB is allocated by PyTorch, and 20.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 2 has a total capacity of 79.11 GiB of which 760.94 MiB is free. Including non-PyTorch memory, this process has 78.36 GiB memory in use. Of the allocated memory 53.44 GiB is allocated by PyTorch, and 24.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 796.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 54.42 GiB is allocated by PyTorch, and 23.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 864.94 MiB is free. Including non-PyTorch memory, this process has 78.26 GiB memory in use. Of the allocated memory 53.79 GiB is allocated by PyTorch, and 23.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 55.81 GiB is allocated by PyTorch, and 21.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 55.37 GiB is allocated by PyTorch, and 22.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.42 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 58.54 GiB is allocated by PyTorch, and 19.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 118.94 MiB is free. Including non-PyTorch memory, this process has 78.98 GiB memory in use. Of the allocated memory 55.01 GiB is allocated by PyTorch, and 23.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 24.94 MiB is free. Including non-PyTorch memory, this process has 79.08 GiB memory in use. Of the allocated memory 53.75 GiB is allocated by PyTorch, and 24.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.33 GiB. GPU 0 has a total capacity of 79.11 GiB of which 798.94 MiB is free. Including non-PyTorch memory, this process has 78.32 GiB memory in use. Of the allocated memory 52.91 GiB is allocated by PyTorch, and 24.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 730.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 24.94 MiB is free. Including non-PyTorch memory, this process has 79.08 GiB memory in use. Of the allocated memory 54.34 GiB is allocated by PyTorch, and 24.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 24.94 MiB is free. Including non-PyTorch memory, this process has 79.08 GiB memory in use. Of the allocated memory 54.07 GiB is allocated by PyTorch, and 24.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 55.27 GiB is allocated by PyTorch, and 22.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 24.94 MiB is free. Including non-PyTorch memory, this process has 79.08 GiB memory in use. Of the allocated memory 54.77 GiB is allocated by PyTorch, and 23.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 54.81 GiB is allocated by PyTorch, and 22.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 682.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 116.94 MiB is free. Including non-PyTorch memory, this process has 78.99 GiB memory in use. Of the allocated memory 51.69 GiB is allocated by PyTorch, and 26.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 754.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 110.94 MiB is free. Including non-PyTorch memory, this process has 78.99 GiB memory in use. Of the allocated memory 55.86 GiB is allocated by PyTorch, and 22.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.33 GiB. GPU 0 has a total capacity of 79.11 GiB of which 66.94 MiB is free. Including non-PyTorch memory, this process has 79.04 GiB memory in use. Of the allocated memory 52.95 GiB is allocated by PyTorch, and 25.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 758.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 54.56 GiB is allocated by PyTorch, and 23.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.30 GiB. GPU 0 has a total capacity of 79.11 GiB of which 66.94 MiB is free. Including non-PyTorch memory, this process has 79.04 GiB memory in use. Of the allocated memory 51.56 GiB is allocated by PyTorch, and 26.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 740.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 24.94 MiB is free. Including non-PyTorch memory, this process has 79.08 GiB memory in use. Of the allocated memory 54.68 GiB is allocated by PyTorch, and 23.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 2 has a total capacity of 79.11 GiB of which 760.94 MiB is free. Including non-PyTorch memory, this process has 78.36 GiB memory in use. Of the allocated memory 54.56 GiB is allocated by PyTorch, and 23.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 2 has a total capacity of 79.11 GiB of which 760.94 MiB is free. Including non-PyTorch memory, this process has 78.36 GiB memory in use. Of the allocated memory 54.63 GiB is allocated by PyTorch, and 23.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 110.94 MiB is free. Including non-PyTorch memory, this process has 78.99 GiB memory in use. Of the allocated memory 55.28 GiB is allocated by PyTorch, and 23.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 2 has a total capacity of 79.11 GiB of which 760.94 MiB is free. Including non-PyTorch memory, this process has 78.36 GiB memory in use. Of the allocated memory 53.70 GiB is allocated by PyTorch, and 24.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 56.09 GiB is allocated by PyTorch, and 21.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.30 GiB. GPU 0 has a total capacity of 79.11 GiB of which 762.94 MiB is free. Including non-PyTorch memory, this process has 78.36 GiB memory in use. Of the allocated memory 50.80 GiB is allocated by PyTorch, and 26.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 1 has a total capacity of 79.11 GiB of which 110.94 MiB is free. Including non-PyTorch memory, this process has 78.99 GiB memory in use. Of the allocated memory 55.36 GiB is allocated by PyTorch, and 22.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 764.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 55.34 GiB is allocated by PyTorch, and 22.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 1 has a total capacity of 79.11 GiB of which 104.94 MiB is free. Including non-PyTorch memory, this process has 79.00 GiB memory in use. Of the allocated memory 55.84 GiB is allocated by PyTorch, and 22.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 55.96 GiB is allocated by PyTorch, and 21.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.30 GiB. GPU 0 has a total capacity of 79.11 GiB of which 792.94 MiB is free. Including non-PyTorch memory, this process has 78.33 GiB memory in use. Of the allocated memory 50.98 GiB is allocated by PyTorch, and 26.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 694.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 154.94 MiB is free. Including non-PyTorch memory, this process has 78.95 GiB memory in use. Of the allocated memory 52.34 GiB is allocated by PyTorch, and 25.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 756.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 55.16 GiB is allocated by PyTorch, and 22.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 778.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 86.94 MiB is free. Including non-PyTorch memory, this process has 79.02 GiB memory in use. Of the allocated memory 57.13 GiB is allocated by PyTorch, and 21.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.32 GiB. GPU 0 has a total capacity of 79.11 GiB of which 842.94 MiB is free. Including non-PyTorch memory, this process has 78.28 GiB memory in use. Of the allocated memory 52.58 GiB is allocated by PyTorch, and 25.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.31 GiB. GPU 0 has a total capacity of 79.11 GiB of which 912.94 MiB is free. Including non-PyTorch memory, this process has 78.21 GiB memory in use. Of the allocated memory 52.13 GiB is allocated by PyTorch, and 25.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 864.94 MiB is free. Including non-PyTorch memory, this process has 78.26 GiB memory in use. Of the allocated memory 54.66 GiB is allocated by PyTorch, and 22.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 858.94 MiB is free. Including non-PyTorch memory, this process has 78.26 GiB memory in use. Of the allocated memory 53.41 GiB is allocated by PyTorch, and 24.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 96.94 MiB is free. Including non-PyTorch memory, this process has 79.01 GiB memory in use. Of the allocated memory 55.26 GiB is allocated by PyTorch, and 23.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 858.94 MiB is free. Including non-PyTorch memory, this process has 78.26 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 23.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 738.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 78.98 GiB memory in use. Of the allocated memory 54.56 GiB is allocated by PyTorch, and 23.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 864.94 MiB is free. Including non-PyTorch memory, this process has 78.26 GiB memory in use. Of the allocated memory 55.37 GiB is allocated by PyTorch, and 22.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 748.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 78.98 GiB memory in use. Of the allocated memory 53.87 GiB is allocated by PyTorch, and 24.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 54.66 GiB is allocated by PyTorch, and 23.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 716.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 554.94 MiB is free. Including non-PyTorch memory, this process has 78.56 GiB memory in use. Of the allocated memory 52.42 GiB is allocated by PyTorch, and 25.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 740.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 112.94 MiB is free. Including non-PyTorch memory, this process has 78.99 GiB memory in use. Of the allocated memory 55.03 GiB is allocated by PyTorch, and 23.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.40 GiB. GPU 1 has a total capacity of 79.11 GiB of which 864.94 MiB is free. Including non-PyTorch memory, this process has 78.26 GiB memory in use. Of the allocated memory 56.16 GiB is allocated by PyTorch, and 21.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.39 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 56.79 GiB is allocated by PyTorch, and 20.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 2 has a total capacity of 79.11 GiB of which 852.94 MiB is free. Including non-PyTorch memory, this process has 78.27 GiB memory in use. Of the allocated memory 55.24 GiB is allocated by PyTorch, and 22.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 118.94 MiB is free. Including non-PyTorch memory, this process has 78.98 GiB memory in use. Of the allocated memory 55.22 GiB is allocated by PyTorch, and 23.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.40 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 57.39 GiB is allocated by PyTorch, and 20.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 686.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 554.94 MiB is free. Including non-PyTorch memory, this process has 78.56 GiB memory in use. Of the allocated memory 50.48 GiB is allocated by PyTorch, and 27.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 110.94 MiB is free. Including non-PyTorch memory, this process has 78.99 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 22.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 2 has a total capacity of 79.11 GiB of which 852.94 MiB is free. Including non-PyTorch memory, this process has 78.27 GiB memory in use. Of the allocated memory 53.41 GiB is allocated by PyTorch, and 24.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 1 has a total capacity of 79.11 GiB of which 98.94 MiB is free. Including non-PyTorch memory, this process has 79.00 GiB memory in use. Of the allocated memory 56.14 GiB is allocated by PyTorch, and 22.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 774.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 56.01 GiB is allocated by PyTorch, and 21.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 682.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 554.94 MiB is free. Including non-PyTorch memory, this process has 78.56 GiB memory in use. Of the allocated memory 51.49 GiB is allocated by PyTorch, and 26.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 764.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 64.94 MiB is free. Including non-PyTorch memory, this process has 79.04 GiB memory in use. Of the allocated memory 55.08 GiB is allocated by PyTorch, and 23.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 678.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 554.94 MiB is free. Including non-PyTorch memory, this process has 78.56 GiB memory in use. Of the allocated memory 51.58 GiB is allocated by PyTorch, and 26.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 764.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 64.94 MiB is free. Including non-PyTorch memory, this process has 79.04 GiB memory in use. Of the allocated memory 55.66 GiB is allocated by PyTorch, and 22.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 828.94 MiB is free. Including non-PyTorch memory, this process has 78.29 GiB memory in use. Of the allocated memory 53.84 GiB is allocated by PyTorch, and 23.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.30 GiB. GPU 0 has a total capacity of 79.11 GiB of which 554.94 MiB is free. Including non-PyTorch memory, this process has 78.56 GiB memory in use. Of the allocated memory 51.05 GiB is allocated by PyTorch, and 26.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 682.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 554.94 MiB is free. Including non-PyTorch memory, this process has 78.56 GiB memory in use. Of the allocated memory 51.76 GiB is allocated by PyTorch, and 26.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 760.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 98.94 MiB is free. Including non-PyTorch memory, this process has 79.00 GiB memory in use. Of the allocated memory 56.01 GiB is allocated by PyTorch, and 22.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.29 GiB. GPU 0 has a total capacity of 79.11 GiB of which 554.94 MiB is free. Including non-PyTorch memory, this process has 78.56 GiB memory in use. Of the allocated memory 51.01 GiB is allocated by PyTorch, and 26.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 828.94 MiB is free. Including non-PyTorch memory, this process has 78.29 GiB memory in use. Of the allocated memory 54.41 GiB is allocated by PyTorch, and 23.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.30 GiB. GPU 0 has a total capacity of 79.11 GiB of which 554.94 MiB is free. Including non-PyTorch memory, this process has 78.56 GiB memory in use. Of the allocated memory 51.25 GiB is allocated by PyTorch, and 26.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.30 GiB. GPU 0 has a total capacity of 79.11 GiB of which 554.94 MiB is free. Including non-PyTorch memory, this process has 78.56 GiB memory in use. Of the allocated memory 51.31 GiB is allocated by PyTorch, and 26.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 756.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 98.94 MiB is free. Including non-PyTorch memory, this process has 79.00 GiB memory in use. Of the allocated memory 55.71 GiB is allocated by PyTorch, and 22.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.30 GiB. GPU 0 has a total capacity of 79.11 GiB of which 554.94 MiB is free. Including non-PyTorch memory, this process has 78.56 GiB memory in use. Of the allocated memory 51.14 GiB is allocated by PyTorch, and 26.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 744.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 98.94 MiB is free. Including non-PyTorch memory, this process has 79.00 GiB memory in use. Of the allocated memory 55.00 GiB is allocated by PyTorch, and 23.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 680.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 554.94 MiB is free. Including non-PyTorch memory, this process has 78.56 GiB memory in use. Of the allocated memory 51.55 GiB is allocated by PyTorch, and 26.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 1 has a total capacity of 79.11 GiB of which 98.94 MiB is free. Including non-PyTorch memory, this process has 79.00 GiB memory in use. Of the allocated memory 55.87 GiB is allocated by PyTorch, and 22.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.29 GiB. GPU 0 has a total capacity of 79.11 GiB of which 554.94 MiB is free. Including non-PyTorch memory, this process has 78.56 GiB memory in use. Of the allocated memory 50.97 GiB is allocated by PyTorch, and 26.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 864.94 MiB is free. Including non-PyTorch memory, this process has 78.26 GiB memory in use. Of the allocated memory 55.56 GiB is allocated by PyTorch, and 22.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 678.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 554.94 MiB is free. Including non-PyTorch memory, this process has 78.56 GiB memory in use. Of the allocated memory 50.61 GiB is allocated by PyTorch, and 27.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 690.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 554.94 MiB is free. Including non-PyTorch memory, this process has 78.56 GiB memory in use. Of the allocated memory 51.17 GiB is allocated by PyTorch, and 26.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 704.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 554.94 MiB is free. Including non-PyTorch memory, this process has 78.56 GiB memory in use. Of the allocated memory 52.06 GiB is allocated by PyTorch, and 25.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 55.51 GiB is allocated by PyTorch, and 22.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 744.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 78.98 GiB memory in use. Of the allocated memory 54.61 GiB is allocated by PyTorch, and 23.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 112.94 MiB is free. Including non-PyTorch memory, this process has 78.99 GiB memory in use. Of the allocated memory 55.26 GiB is allocated by PyTorch, and 23.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 2 has a total capacity of 79.11 GiB of which 88.94 MiB is free. Including non-PyTorch memory, this process has 79.01 GiB memory in use. Of the allocated memory 54.28 GiB is allocated by PyTorch, and 24.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 88.94 MiB is free. Including non-PyTorch memory, this process has 79.01 GiB memory in use. Of the allocated memory 54.03 GiB is allocated by PyTorch, and 24.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 1 has a total capacity of 79.11 GiB of which 102.94 MiB is free. Including non-PyTorch memory, this process has 79.00 GiB memory in use. Of the allocated memory 55.39 GiB is allocated by PyTorch, and 22.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 1 has a total capacity of 79.11 GiB of which 986.94 MiB is free. Including non-PyTorch memory, this process has 78.14 GiB memory in use. Of the allocated memory 55.37 GiB is allocated by PyTorch, and 22.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 79.11 GiB of which 1.37 GiB is free. Including non-PyTorch memory, this process has 77.73 GiB memory in use. Of the allocated memory 60.68 GiB is allocated by PyTorch, and 16.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 88.94 MiB is free. Including non-PyTorch memory, this process has 79.01 GiB memory in use. Of the allocated memory 53.62 GiB is allocated by PyTorch, and 24.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 986.94 MiB is free. Including non-PyTorch memory, this process has 78.14 GiB memory in use. Of the allocated memory 54.55 GiB is allocated by PyTorch, and 22.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 986.94 MiB is free. Including non-PyTorch memory, this process has 78.14 GiB memory in use. Of the allocated memory 54.07 GiB is allocated by PyTorch, and 23.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 55.16 GiB is allocated by PyTorch, and 22.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 240.94 MiB is free. Including non-PyTorch memory, this process has 78.87 GiB memory in use. Of the allocated memory 54.63 GiB is allocated by PyTorch, and 23.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 986.94 MiB is free. Including non-PyTorch memory, this process has 78.14 GiB memory in use. Of the allocated memory 55.34 GiB is allocated by PyTorch, and 22.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 986.94 MiB is free. Including non-PyTorch memory, this process has 78.14 GiB memory in use. Of the allocated memory 53.78 GiB is allocated by PyTorch, and 23.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 218.94 MiB is free. Including non-PyTorch memory, this process has 78.89 GiB memory in use. Of the allocated memory 55.38 GiB is allocated by PyTorch, and 22.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 752.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 76.94 MiB is free. Including non-PyTorch memory, this process has 79.03 GiB memory in use. Of the allocated memory 55.43 GiB is allocated by PyTorch, and 22.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 756.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 218.94 MiB is free. Including non-PyTorch memory, this process has 78.89 GiB memory in use. Of the allocated memory 55.92 GiB is allocated by PyTorch, and 22.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 748.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 76.94 MiB is free. Including non-PyTorch memory, this process has 79.03 GiB memory in use. Of the allocated memory 53.74 GiB is allocated by PyTorch, and 24.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 1 has a total capacity of 79.11 GiB of which 980.94 MiB is free. Including non-PyTorch memory, this process has 78.14 GiB memory in use. Of the allocated memory 56.29 GiB is allocated by PyTorch, and 21.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 76.94 MiB is free. Including non-PyTorch memory, this process has 79.03 GiB memory in use. Of the allocated memory 53.52 GiB is allocated by PyTorch, and 24.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 980.94 MiB is free. Including non-PyTorch memory, this process has 78.14 GiB memory in use. Of the allocated memory 55.33 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 56.02 GiB is allocated by PyTorch, and 21.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 79.11 GiB of which 1.37 GiB is free. Including non-PyTorch memory, this process has 77.73 GiB memory in use. Of the allocated memory 60.78 GiB is allocated by PyTorch, and 16.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 980.94 MiB is free. Including non-PyTorch memory, this process has 78.14 GiB memory in use. Of the allocated memory 54.63 GiB is allocated by PyTorch, and 22.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 234.94 MiB is free. Including non-PyTorch memory, this process has 78.87 GiB memory in use. Of the allocated memory 54.97 GiB is allocated by PyTorch, and 23.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 79.11 GiB of which 550.94 MiB is free. Including non-PyTorch memory, this process has 78.56 GiB memory in use. Of the allocated memory 60.77 GiB is allocated by PyTorch, and 17.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 980.94 MiB is free. Including non-PyTorch memory, this process has 78.14 GiB memory in use. Of the allocated memory 54.37 GiB is allocated by PyTorch, and 23.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 980.94 MiB is free. Including non-PyTorch memory, this process has 78.14 GiB memory in use. Of the allocated memory 54.70 GiB is allocated by PyTorch, and 22.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 980.94 MiB is free. Including non-PyTorch memory, this process has 78.14 GiB memory in use. Of the allocated memory 54.46 GiB is allocated by PyTorch, and 23.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.47 GiB. GPU 0 has a total capacity of 79.11 GiB of which 726.94 MiB is free. Including non-PyTorch memory, this process has 78.39 GiB memory in use. Of the allocated memory 61.59 GiB is allocated by PyTorch, and 16.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.33 GiB. GPU 2 has a total capacity of 79.11 GiB of which 76.94 MiB is free. Including non-PyTorch memory, this process has 79.03 GiB memory in use. Of the allocated memory 53.45 GiB is allocated by PyTorch, and 24.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 772.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 48.94 MiB is free. Including non-PyTorch memory, this process has 79.05 GiB memory in use. Of the allocated memory 56.29 GiB is allocated by PyTorch, and 22.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 55.13 GiB is allocated by PyTorch, and 22.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 980.94 MiB is free. Including non-PyTorch memory, this process has 78.14 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 22.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 2 has a total capacity of 79.11 GiB of which 48.94 MiB is free. Including non-PyTorch memory, this process has 79.05 GiB memory in use. Of the allocated memory 53.64 GiB is allocated by PyTorch, and 24.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 240.94 MiB is free. Including non-PyTorch memory, this process has 78.87 GiB memory in use. Of the allocated memory 54.94 GiB is allocated by PyTorch, and 23.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 960.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 196.94 MiB is free. Including non-PyTorch memory, this process has 78.91 GiB memory in use. Of the allocated memory 66.26 GiB is allocated by PyTorch, and 11.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.40 GiB. GPU 1 has a total capacity of 79.11 GiB of which 224.94 MiB is free. Including non-PyTorch memory, this process has 78.88 GiB memory in use. Of the allocated memory 56.13 GiB is allocated by PyTorch, and 22.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 964.94 MiB is free. Including non-PyTorch memory, this process has 78.16 GiB memory in use. Of the allocated memory 55.25 GiB is allocated by PyTorch, and 22.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 760.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 56.07 GiB is allocated by PyTorch, and 21.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 964.94 MiB is free. Including non-PyTorch memory, this process has 78.16 GiB memory in use. Of the allocated memory 54.37 GiB is allocated by PyTorch, and 23.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 888.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 196.94 MiB is free. Including non-PyTorch memory, this process has 78.91 GiB memory in use. Of the allocated memory 62.40 GiB is allocated by PyTorch, and 15.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 55.30 GiB is allocated by PyTorch, and 22.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 744.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 54.37 GiB is allocated by PyTorch, and 23.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 53.93 GiB is allocated by PyTorch, and 24.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 912.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 196.94 MiB is free. Including non-PyTorch memory, this process has 78.91 GiB memory in use. Of the allocated memory 60.97 GiB is allocated by PyTorch, and 17.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 824.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 57.14 GiB is allocated by PyTorch, and 20.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 55.14 GiB is allocated by PyTorch, and 22.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 2 has a total capacity of 79.11 GiB of which 48.94 MiB is free. Including non-PyTorch memory, this process has 79.05 GiB memory in use. Of the allocated memory 53.69 GiB is allocated by PyTorch, and 24.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 54.82 GiB is allocated by PyTorch, and 23.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.39 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 56.63 GiB is allocated by PyTorch, and 21.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 54.68 GiB is allocated by PyTorch, and 23.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 752.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 55.52 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 746.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 55.36 GiB is allocated by PyTorch, and 22.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 55.34 GiB is allocated by PyTorch, and 22.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.49 GiB. GPU 0 has a total capacity of 79.11 GiB of which 196.94 MiB is free. Including non-PyTorch memory, this process has 78.91 GiB memory in use. Of the allocated memory 63.37 GiB is allocated by PyTorch, and 14.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 2 has a total capacity of 79.11 GiB of which 820.94 MiB is free. Including non-PyTorch memory, this process has 78.30 GiB memory in use. Of the allocated memory 55.96 GiB is allocated by PyTorch, and 21.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.49 GiB. GPU 0 has a total capacity of 79.11 GiB of which 196.94 MiB is free. Including non-PyTorch memory, this process has 78.91 GiB memory in use. Of the allocated memory 63.02 GiB is allocated by PyTorch, and 15.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 22.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 834.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 750.94 MiB is free. Including non-PyTorch memory, this process has 78.37 GiB memory in use. Of the allocated memory 53.63 GiB is allocated by PyTorch, and 24.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 54.25 GiB is allocated by PyTorch, and 23.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 2 has a total capacity of 79.11 GiB of which 750.94 MiB is free. Including non-PyTorch memory, this process has 78.37 GiB memory in use. Of the allocated memory 53.50 GiB is allocated by PyTorch, and 24.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 53.60 GiB is allocated by PyTorch, and 24.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 54.63 GiB is allocated by PyTorch, and 23.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 79.11 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 78.02 GiB memory in use. Of the allocated memory 59.52 GiB is allocated by PyTorch, and 17.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 54.34 GiB is allocated by PyTorch, and 23.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.39 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 55.82 GiB is allocated by PyTorch, and 21.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 55.40 GiB is allocated by PyTorch, and 22.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 54.60 GiB is allocated by PyTorch, and 23.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 750.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 55.68 GiB is allocated by PyTorch, and 22.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.40 GiB. GPU 0 has a total capacity of 79.11 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 78.02 GiB memory in use. Of the allocated memory 56.99 GiB is allocated by PyTorch, and 20.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.47 GiB. GPU 0 has a total capacity of 79.11 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 78.02 GiB memory in use. Of the allocated memory 61.94 GiB is allocated by PyTorch, and 15.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 22.94 MiB is free. Including non-PyTorch memory, this process has 79.08 GiB memory in use. Of the allocated memory 54.03 GiB is allocated by PyTorch, and 24.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 54.35 GiB is allocated by PyTorch, and 23.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacity of 79.11 GiB of which 300.94 MiB is free. Including non-PyTorch memory, this process has 78.81 GiB memory in use. Of the allocated memory 58.57 GiB is allocated by PyTorch, and 19.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 55.04 GiB is allocated by PyTorch, and 23.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 55.72 GiB is allocated by PyTorch, and 22.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 55.78 GiB is allocated by PyTorch, and 22.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 2 has a total capacity of 79.11 GiB of which 750.94 MiB is free. Including non-PyTorch memory, this process has 78.37 GiB memory in use. Of the allocated memory 55.60 GiB is allocated by PyTorch, and 22.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.48 GiB. GPU 0 has a total capacity of 79.11 GiB of which 234.94 MiB is free. Including non-PyTorch memory, this process has 78.87 GiB memory in use. Of the allocated memory 62.09 GiB is allocated by PyTorch, and 16.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 760.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 55.35 GiB is allocated by PyTorch, and 22.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 1 has a total capacity of 79.11 GiB of which 360.94 MiB is free. Including non-PyTorch memory, this process has 78.75 GiB memory in use. Of the allocated memory 55.87 GiB is allocated by PyTorch, and 22.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 55.12 GiB is allocated by PyTorch, and 22.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 850.94 MiB is free. Including non-PyTorch memory, this process has 78.27 GiB memory in use. Of the allocated memory 54.38 GiB is allocated by PyTorch, and 23.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 54.37 GiB is allocated by PyTorch, and 22.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 794.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 56.87 GiB is allocated by PyTorch, and 20.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 760.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 484.94 MiB is free. Including non-PyTorch memory, this process has 78.63 GiB memory in use. Of the allocated memory 54.62 GiB is allocated by PyTorch, and 23.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 484.94 MiB is free. Including non-PyTorch memory, this process has 78.63 GiB memory in use. Of the allocated memory 54.95 GiB is allocated by PyTorch, and 23.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 726.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 124.94 MiB is free. Including non-PyTorch memory, this process has 78.98 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 24.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 740.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 484.94 MiB is free. Including non-PyTorch memory, this process has 78.63 GiB memory in use. Of the allocated memory 54.81 GiB is allocated by PyTorch, and 23.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.40 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 57.45 GiB is allocated by PyTorch, and 20.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 2 has a total capacity of 79.11 GiB of which 110.94 MiB is free. Including non-PyTorch memory, this process has 78.99 GiB memory in use. Of the allocated memory 54.69 GiB is allocated by PyTorch, and 23.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.48 GiB. GPU 0 has a total capacity of 79.11 GiB of which 228.94 MiB is free. Including non-PyTorch memory, this process has 78.88 GiB memory in use. Of the allocated memory 62.60 GiB is allocated by PyTorch, and 15.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 740.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 106.94 MiB is free. Including non-PyTorch memory, this process has 79.00 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 24.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 752.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 484.94 MiB is free. Including non-PyTorch memory, this process has 78.63 GiB memory in use. Of the allocated memory 54.81 GiB is allocated by PyTorch, and 23.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 794.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 57.01 GiB is allocated by PyTorch, and 20.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 484.94 MiB is free. Including non-PyTorch memory, this process has 78.63 GiB memory in use. Of the allocated memory 55.31 GiB is allocated by PyTorch, and 22.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 806.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 776.94 MiB is free. Including non-PyTorch memory, this process has 78.34 GiB memory in use. Of the allocated memory 54.20 GiB is allocated by PyTorch, and 23.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 776.94 MiB is free. Including non-PyTorch memory, this process has 78.34 GiB memory in use. Of the allocated memory 54.28 GiB is allocated by PyTorch, and 23.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.40 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 57.43 GiB is allocated by PyTorch, and 20.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 484.94 MiB is free. Including non-PyTorch memory, this process has 78.63 GiB memory in use. Of the allocated memory 55.02 GiB is allocated by PyTorch, and 22.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 484.94 MiB is free. Including non-PyTorch memory, this process has 78.63 GiB memory in use. Of the allocated memory 54.81 GiB is allocated by PyTorch, and 23.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.44 GiB. GPU 0 has a total capacity of 79.11 GiB of which 228.94 MiB is free. Including non-PyTorch memory, this process has 78.88 GiB memory in use. Of the allocated memory 59.84 GiB is allocated by PyTorch, and 18.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 55.18 GiB is allocated by PyTorch, and 22.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 484.94 MiB is free. Including non-PyTorch memory, this process has 78.63 GiB memory in use. Of the allocated memory 54.81 GiB is allocated by PyTorch, and 23.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 484.94 MiB is free. Including non-PyTorch memory, this process has 78.63 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 23.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 776.94 MiB is free. Including non-PyTorch memory, this process has 78.34 GiB memory in use. Of the allocated memory 53.54 GiB is allocated by PyTorch, and 24.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 484.94 MiB is free. Including non-PyTorch memory, this process has 78.63 GiB memory in use. Of the allocated memory 54.63 GiB is allocated by PyTorch, and 23.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 54.61 GiB is allocated by PyTorch, and 22.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 53.56 GiB is allocated by PyTorch, and 23.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.33 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 53.08 GiB is allocated by PyTorch, and 24.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.49 GiB. GPU 0 has a total capacity of 79.11 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 78.02 GiB memory in use. Of the allocated memory 63.02 GiB is allocated by PyTorch, and 14.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 500.94 MiB is free. Including non-PyTorch memory, this process has 78.61 GiB memory in use. Of the allocated memory 54.75 GiB is allocated by PyTorch, and 23.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 742.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 500.94 MiB is free. Including non-PyTorch memory, this process has 78.61 GiB memory in use. Of the allocated memory 54.88 GiB is allocated by PyTorch, and 23.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 55.17 GiB is allocated by PyTorch, and 22.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 732.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 500.94 MiB is free. Including non-PyTorch memory, this process has 78.61 GiB memory in use. Of the allocated memory 53.83 GiB is allocated by PyTorch, and 24.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 3 has a total capacity of 79.11 GiB of which 688.94 MiB is free. Including non-PyTorch memory, this process has 78.43 GiB memory in use. Of the allocated memory 56.27 GiB is allocated by PyTorch, and 21.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.39 GiB. GPU 3 has a total capacity of 79.11 GiB of which 144.94 MiB is free. Including non-PyTorch memory, this process has 78.96 GiB memory in use. Of the allocated memory 56.22 GiB is allocated by PyTorch, and 22.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 500.94 MiB is free. Including non-PyTorch memory, this process has 78.61 GiB memory in use. Of the allocated memory 54.66 GiB is allocated by PyTorch, and 23.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 2 has a total capacity of 79.11 GiB of which 852.94 MiB is free. Including non-PyTorch memory, this process has 78.27 GiB memory in use. Of the allocated memory 55.05 GiB is allocated by PyTorch, and 22.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 54.66 GiB is allocated by PyTorch, and 22.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.40 GiB. GPU 3 has a total capacity of 79.11 GiB of which 144.94 MiB is free. Including non-PyTorch memory, this process has 78.96 GiB memory in use. Of the allocated memory 57.02 GiB is allocated by PyTorch, and 21.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 53.65 GiB is allocated by PyTorch, and 23.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.39 GiB. GPU 3 has a total capacity of 79.11 GiB of which 144.94 MiB is free. Including non-PyTorch memory, this process has 78.96 GiB memory in use. Of the allocated memory 56.88 GiB is allocated by PyTorch, and 21.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 54.93 GiB is allocated by PyTorch, and 22.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.47 GiB. GPU 0 has a total capacity of 79.11 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 78.02 GiB memory in use. Of the allocated memory 61.81 GiB is allocated by PyTorch, and 15.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 760.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 144.94 MiB is free. Including non-PyTorch memory, this process has 78.96 GiB memory in use. Of the allocated memory 55.44 GiB is allocated by PyTorch, and 22.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 804.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 144.94 MiB is free. Including non-PyTorch memory, this process has 78.96 GiB memory in use. Of the allocated memory 57.77 GiB is allocated by PyTorch, and 20.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 53.53 GiB is allocated by PyTorch, and 23.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.40 GiB. GPU 3 has a total capacity of 79.11 GiB of which 144.94 MiB is free. Including non-PyTorch memory, this process has 78.96 GiB memory in use. Of the allocated memory 57.36 GiB is allocated by PyTorch, and 20.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 54.47 GiB is allocated by PyTorch, and 22.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 144.94 MiB is free. Including non-PyTorch memory, this process has 78.96 GiB memory in use. Of the allocated memory 55.19 GiB is allocated by PyTorch, and 23.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 876.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 512.94 MiB is free. Including non-PyTorch memory, this process has 78.60 GiB memory in use. Of the allocated memory 60.06 GiB is allocated by PyTorch, and 17.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 3 has a total capacity of 79.11 GiB of which 144.94 MiB is free. Including non-PyTorch memory, this process has 78.96 GiB memory in use. Of the allocated memory 56.00 GiB is allocated by PyTorch, and 22.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 53.85 GiB is allocated by PyTorch, and 23.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 766.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 144.94 MiB is free. Including non-PyTorch memory, this process has 78.96 GiB memory in use. Of the allocated memory 55.94 GiB is allocated by PyTorch, and 22.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 54.11 GiB is allocated by PyTorch, and 23.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 54.31 GiB is allocated by PyTorch, and 22.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.33 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 53.47 GiB is allocated by PyTorch, and 23.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 1002.94 MiB is free. Including non-PyTorch memory, this process has 78.12 GiB memory in use. Of the allocated memory 55.54 GiB is allocated by PyTorch, and 21.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.48 GiB. GPU 0 has a total capacity of 79.11 GiB of which 512.94 MiB is free. Including non-PyTorch memory, this process has 78.60 GiB memory in use. Of the allocated memory 62.56 GiB is allocated by PyTorch, and 15.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 756.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 488.94 MiB is free. Including non-PyTorch memory, this process has 78.62 GiB memory in use. Of the allocated memory 56.01 GiB is allocated by PyTorch, and 21.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 852.94 MiB is free. Including non-PyTorch memory, this process has 78.27 GiB memory in use. Of the allocated memory 54.02 GiB is allocated by PyTorch, and 23.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 3 has a total capacity of 79.11 GiB of which 1002.94 MiB is free. Including non-PyTorch memory, this process has 78.12 GiB memory in use. Of the allocated memory 54.81 GiB is allocated by PyTorch, and 22.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.44 GiB. GPU 0 has a total capacity of 79.11 GiB of which 512.94 MiB is free. Including non-PyTorch memory, this process has 78.60 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 17.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 488.94 MiB is free. Including non-PyTorch memory, this process has 78.62 GiB memory in use. Of the allocated memory 55.26 GiB is allocated by PyTorch, and 22.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.39 GiB. GPU 3 has a total capacity of 79.11 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 78.04 GiB memory in use. Of the allocated memory 56.11 GiB is allocated by PyTorch, and 21.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 79.11 GiB of which 512.94 MiB is free. Including non-PyTorch memory, this process has 78.60 GiB memory in use. Of the allocated memory 59.02 GiB is allocated by PyTorch, and 18.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.39 GiB. GPU 3 has a total capacity of 79.11 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 78.04 GiB memory in use. Of the allocated memory 55.74 GiB is allocated by PyTorch, and 21.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 852.94 MiB is free. Including non-PyTorch memory, this process has 78.27 GiB memory in use. Of the allocated memory 53.90 GiB is allocated by PyTorch, and 23.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 79.11 GiB of which 1.39 GiB is free. Including non-PyTorch memory, this process has 77.71 GiB memory in use. Of the allocated memory 58.53 GiB is allocated by PyTorch, and 18.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 780.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 488.94 MiB is free. Including non-PyTorch memory, this process has 78.62 GiB memory in use. Of the allocated memory 56.59 GiB is allocated by PyTorch, and 21.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 488.94 MiB is free. Including non-PyTorch memory, this process has 78.62 GiB memory in use. Of the allocated memory 54.84 GiB is allocated by PyTorch, and 23.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.40 GiB. GPU 0 has a total capacity of 79.11 GiB of which 1.39 GiB is free. Including non-PyTorch memory, this process has 77.71 GiB memory in use. Of the allocated memory 57.01 GiB is allocated by PyTorch, and 20.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 826.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 126.94 MiB is free. Including non-PyTorch memory, this process has 78.98 GiB memory in use. Of the allocated memory 56.40 GiB is allocated by PyTorch, and 21.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 3 has a total capacity of 79.11 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 78.04 GiB memory in use. Of the allocated memory 54.94 GiB is allocated by PyTorch, and 22.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 488.94 MiB is free. Including non-PyTorch memory, this process has 78.62 GiB memory in use. Of the allocated memory 54.45 GiB is allocated by PyTorch, and 23.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 3 has a total capacity of 79.11 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 78.04 GiB memory in use. Of the allocated memory 54.14 GiB is allocated by PyTorch, and 23.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 3 has a total capacity of 79.11 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 78.04 GiB memory in use. Of the allocated memory 54.84 GiB is allocated by PyTorch, and 22.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.47 GiB. GPU 0 has a total capacity of 79.11 GiB of which 80.94 MiB is free. Including non-PyTorch memory, this process has 79.02 GiB memory in use. Of the allocated memory 62.03 GiB is allocated by PyTorch, and 16.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 742.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 488.94 MiB is free. Including non-PyTorch memory, this process has 78.62 GiB memory in use. Of the allocated memory 55.03 GiB is allocated by PyTorch, and 22.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 828.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 80.94 MiB is free. Including non-PyTorch memory, this process has 79.02 GiB memory in use. Of the allocated memory 59.91 GiB is allocated by PyTorch, and 18.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 3 has a total capacity of 79.11 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 78.04 GiB memory in use. Of the allocated memory 54.15 GiB is allocated by PyTorch, and 23.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 56.55 GiB is allocated by PyTorch, and 21.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 54.92 GiB is allocated by PyTorch, and 22.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 53.80 GiB is allocated by PyTorch, and 23.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 754.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 53.72 GiB is allocated by PyTorch, and 24.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 79.11 GiB of which 80.94 MiB is free. Including non-PyTorch memory, this process has 79.02 GiB memory in use. Of the allocated memory 59.16 GiB is allocated by PyTorch, and 19.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 55.23 GiB is allocated by PyTorch, and 22.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.33 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 52.95 GiB is allocated by PyTorch, and 24.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 756.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 55.49 GiB is allocated by PyTorch, and 22.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 54.08 GiB is allocated by PyTorch, and 23.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 54.86 GiB is allocated by PyTorch, and 23.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.33 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 52.88 GiB is allocated by PyTorch, and 24.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.33 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 53.38 GiB is allocated by PyTorch, and 23.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 54.09 GiB is allocated by PyTorch, and 23.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 55.19 GiB is allocated by PyTorch, and 22.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 778.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 55.05 GiB is allocated by PyTorch, and 22.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 55.78 GiB is allocated by PyTorch, and 22.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 53.46 GiB is allocated by PyTorch, and 23.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 118.94 MiB is free. Including non-PyTorch memory, this process has 78.98 GiB memory in use. Of the allocated memory 54.11 GiB is allocated by PyTorch, and 24.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 53.76 GiB is allocated by PyTorch, and 24.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 77.88 GiB memory in use. Of the allocated memory 54.50 GiB is allocated by PyTorch, and 22.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 766.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 55.27 GiB is allocated by PyTorch, and 22.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 2 has a total capacity of 79.11 GiB of which 850.94 MiB is free. Including non-PyTorch memory, this process has 78.27 GiB memory in use. Of the allocated memory 55.75 GiB is allocated by PyTorch, and 21.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.44 GiB. GPU 0 has a total capacity of 79.11 GiB of which 80.94 MiB is free. Including non-PyTorch memory, this process has 79.02 GiB memory in use. Of the allocated memory 59.74 GiB is allocated by PyTorch, and 18.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.33 GiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 53.27 GiB is allocated by PyTorch, and 24.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 758.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 23.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 78.98 GiB memory in use. Of the allocated memory 54.02 GiB is allocated by PyTorch, and 24.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 55.19 GiB is allocated by PyTorch, and 22.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 876.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 76.94 MiB is free. Including non-PyTorch memory, this process has 79.03 GiB memory in use. Of the allocated memory 62.28 GiB is allocated by PyTorch, and 16.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 756.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 55.35 GiB is allocated by PyTorch, and 22.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.49 GiB. GPU 0 has a total capacity of 79.11 GiB of which 62.94 MiB is free. Including non-PyTorch memory, this process has 79.04 GiB memory in use. Of the allocated memory 63.00 GiB is allocated by PyTorch, and 15.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 54.97 GiB is allocated by PyTorch, and 23.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 750.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 222.94 MiB is free. Including non-PyTorch memory, this process has 78.88 GiB memory in use. Of the allocated memory 53.79 GiB is allocated by PyTorch, and 24.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 55.19 GiB is allocated by PyTorch, and 22.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 53.61 GiB is allocated by PyTorch, and 24.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacity of 79.11 GiB of which 62.94 MiB is free. Including non-PyTorch memory, this process has 79.04 GiB memory in use. Of the allocated memory 58.45 GiB is allocated by PyTorch, and 19.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 902.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 62.94 MiB is free. Including non-PyTorch memory, this process has 79.04 GiB memory in use. Of the allocated memory 60.84 GiB is allocated by PyTorch, and 17.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 54.52 GiB is allocated by PyTorch, and 23.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 54.70 GiB is allocated by PyTorch, and 23.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 54.35 GiB is allocated by PyTorch, and 23.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 54.28 GiB is allocated by PyTorch, and 23.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 54.99 GiB is allocated by PyTorch, and 23.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.49 GiB. GPU 0 has a total capacity of 79.11 GiB of which 56.94 MiB is free. Including non-PyTorch memory, this process has 79.04 GiB memory in use. Of the allocated memory 62.71 GiB is allocated by PyTorch, and 15.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 22.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 756.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 22.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 2 has a total capacity of 79.11 GiB of which 222.94 MiB is free. Including non-PyTorch memory, this process has 78.88 GiB memory in use. Of the allocated memory 53.88 GiB is allocated by PyTorch, and 24.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 952.94 MiB is free. Including non-PyTorch memory, this process has 78.17 GiB memory in use. Of the allocated memory 63.83 GiB is allocated by PyTorch, and 13.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 54.17 GiB is allocated by PyTorch, and 23.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 55.12 GiB is allocated by PyTorch, and 22.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 1.03 GiB is free. Including non-PyTorch memory, this process has 78.07 GiB memory in use. Of the allocated memory 53.46 GiB is allocated by PyTorch, and 23.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.47 GiB. GPU 0 has a total capacity of 79.11 GiB of which 88.94 MiB is free. Including non-PyTorch memory, this process has 79.01 GiB memory in use. Of the allocated memory 61.91 GiB is allocated by PyTorch, and 16.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.48 GiB. GPU 0 has a total capacity of 79.11 GiB of which 78.94 MiB is free. Including non-PyTorch memory, this process has 79.02 GiB memory in use. Of the allocated memory 62.45 GiB is allocated by PyTorch, and 15.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 55.90 GiB is allocated by PyTorch, and 22.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 740.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 55.12 GiB is allocated by PyTorch, and 22.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.49 GiB. GPU 0 has a total capacity of 79.11 GiB of which 78.94 MiB is free. Including non-PyTorch memory, this process has 79.02 GiB memory in use. Of the allocated memory 62.97 GiB is allocated by PyTorch, and 15.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 54.26 GiB is allocated by PyTorch, and 23.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 54.34 GiB is allocated by PyTorch, and 23.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 55.10 GiB is allocated by PyTorch, and 22.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 53.79 GiB is allocated by PyTorch, and 23.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 79.11 GiB of which 952.94 MiB is free. Including non-PyTorch memory, this process has 78.17 GiB memory in use. Of the allocated memory 60.35 GiB is allocated by PyTorch, and 17.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 778.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 53.82 GiB is allocated by PyTorch, and 23.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 2 has a total capacity of 79.11 GiB of which 314.94 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 54.90 GiB is allocated by PyTorch, and 23.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 738.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 314.94 MiB is free. Including non-PyTorch memory, this process has 78.79 GiB memory in use. Of the allocated memory 54.92 GiB is allocated by PyTorch, and 23.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 754.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 55.43 GiB is allocated by PyTorch, and 22.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 53.93 GiB is allocated by PyTorch, and 23.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 53.59 GiB is allocated by PyTorch, and 24.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 54.14 GiB is allocated by PyTorch, and 23.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 748.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 55.06 GiB is allocated by PyTorch, and 22.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 748.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 55.03 GiB is allocated by PyTorch, and 22.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 54.63 GiB is allocated by PyTorch, and 23.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.33 GiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 53.24 GiB is allocated by PyTorch, and 24.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 2 has a total capacity of 79.11 GiB of which 1.03 GiB is free. Including non-PyTorch memory, this process has 78.07 GiB memory in use. Of the allocated memory 54.78 GiB is allocated by PyTorch, and 22.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 750.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 54.88 GiB is allocated by PyTorch, and 23.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 858.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 61.45 GiB is allocated by PyTorch, and 16.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 53.90 GiB is allocated by PyTorch, and 23.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.47 GiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 61.64 GiB is allocated by PyTorch, and 16.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 54.42 GiB is allocated by PyTorch, and 23.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 1.13 GiB is free. Including non-PyTorch memory, this process has 77.97 GiB memory in use. Of the allocated memory 54.38 GiB is allocated by PyTorch, and 22.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 790.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 57.91 GiB is allocated by PyTorch, and 20.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 774.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 56.29 GiB is allocated by PyTorch, and 21.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 738.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 414.94 MiB is free. Including non-PyTorch memory, this process has 78.70 GiB memory in use. Of the allocated memory 54.52 GiB is allocated by PyTorch, and 23.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.40 GiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 57.35 GiB is allocated by PyTorch, and 20.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 58.84 GiB is allocated by PyTorch, and 19.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 802.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 56.88 GiB is allocated by PyTorch, and 21.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 730.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 414.94 MiB is free. Including non-PyTorch memory, this process has 78.70 GiB memory in use. Of the allocated memory 53.60 GiB is allocated by PyTorch, and 24.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.39 GiB. GPU 2 has a total capacity of 79.11 GiB of which 346.94 MiB is free. Including non-PyTorch memory, this process has 78.76 GiB memory in use. Of the allocated memory 55.68 GiB is allocated by PyTorch, and 22.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 770.00 MiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 55.87 GiB is allocated by PyTorch, and 22.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 55.34 GiB is allocated by PyTorch, and 22.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 746.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 346.94 MiB is free. Including non-PyTorch memory, this process has 78.76 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 23.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 346.94 MiB is free. Including non-PyTorch memory, this process has 78.76 GiB memory in use. Of the allocated memory 54.26 GiB is allocated by PyTorch, and 23.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 346.94 MiB is free. Including non-PyTorch memory, this process has 78.76 GiB memory in use. Of the allocated memory 53.76 GiB is allocated by PyTorch, and 24.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 2 has a total capacity of 79.11 GiB of which 346.94 MiB is free. Including non-PyTorch memory, this process has 78.76 GiB memory in use. Of the allocated memory 55.09 GiB is allocated by PyTorch, and 23.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 346.94 MiB is free. Including non-PyTorch memory, this process has 78.76 GiB memory in use. Of the allocated memory 54.71 GiB is allocated by PyTorch, and 23.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 55.09 GiB is allocated by PyTorch, and 22.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 740.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 346.94 MiB is free. Including non-PyTorch memory, this process has 78.76 GiB memory in use. Of the allocated memory 52.89 GiB is allocated by PyTorch, and 25.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.41 GiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 57.31 GiB is allocated by PyTorch, and 20.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 728.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 346.94 MiB is free. Including non-PyTorch memory, this process has 78.76 GiB memory in use. Of the allocated memory 52.78 GiB is allocated by PyTorch, and 25.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 55.12 GiB is allocated by PyTorch, and 22.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 6.94 MiB is free. Including non-PyTorch memory, this process has 79.09 GiB memory in use. Of the allocated memory 53.89 GiB is allocated by PyTorch, and 24.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.39 GiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 56.22 GiB is allocated by PyTorch, and 21.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 346.94 MiB is free. Including non-PyTorch memory, this process has 78.76 GiB memory in use. Of the allocated memory 54.31 GiB is allocated by PyTorch, and 23.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 2 has a total capacity of 79.11 GiB of which 346.94 MiB is free. Including non-PyTorch memory, this process has 78.76 GiB memory in use. Of the allocated memory 54.03 GiB is allocated by PyTorch, and 24.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 54.51 GiB is allocated by PyTorch, and 23.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 54.98 GiB is allocated by PyTorch, and 23.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 790.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 57.69 GiB is allocated by PyTorch, and 20.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 760.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 55.32 GiB is allocated by PyTorch, and 22.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.41 GiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 57.91 GiB is allocated by PyTorch, and 20.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 53.70 GiB is allocated by PyTorch, and 24.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 744.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 53.52 GiB is allocated by PyTorch, and 24.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 2 has a total capacity of 79.11 GiB of which 346.94 MiB is free. Including non-PyTorch memory, this process has 78.76 GiB memory in use. Of the allocated memory 54.78 GiB is allocated by PyTorch, and 23.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 58.02 GiB is allocated by PyTorch, and 20.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 2 has a total capacity of 79.11 GiB of which 346.94 MiB is free. Including non-PyTorch memory, this process has 78.76 GiB memory in use. Of the allocated memory 54.09 GiB is allocated by PyTorch, and 24.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 746.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 54.93 GiB is allocated by PyTorch, and 22.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.39 GiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 57.03 GiB is allocated by PyTorch, and 21.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 2: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 2 has a total capacity of 79.11 GiB of which 346.94 MiB is free. Including non-PyTorch memory, this process has 78.76 GiB memory in use. Of the allocated memory 54.55 GiB is allocated by PyTorch, and 23.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 53.96 GiB is allocated by PyTorch, and 23.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.34 GiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 53.33 GiB is allocated by PyTorch, and 24.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 754.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 734.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 54.79 GiB is allocated by PyTorch, and 22.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 4.94 MiB is free. Including non-PyTorch memory, this process has 79.10 GiB memory in use. Of the allocated memory 54.20 GiB is allocated by PyTorch, and 24.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 1 has a total capacity of 79.11 GiB of which 806.94 MiB is free. Including non-PyTorch memory, this process has 78.31 GiB memory in use. Of the allocated memory 59.69 GiB is allocated by PyTorch, and 17.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 77.98 GiB memory in use. Of the allocated memory 56.31 GiB is allocated by PyTorch, and 21.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 59.39 GiB is allocated by PyTorch, and 18.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 58.82 GiB is allocated by PyTorch, and 19.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.41 GiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 57.36 GiB is allocated by PyTorch, and 20.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 774.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 376.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 55.44 GiB is allocated by PyTorch, and 22.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 744.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 376.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 54.72 GiB is allocated by PyTorch, and 23.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 54.16 GiB is allocated by PyTorch, and 23.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 796.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 56.55 GiB is allocated by PyTorch, and 21.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.40 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 77.98 GiB memory in use. Of the allocated memory 57.12 GiB is allocated by PyTorch, and 20.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 778.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 372.94 MiB is free. Including non-PyTorch memory, this process has 78.74 GiB memory in use. Of the allocated memory 57.27 GiB is allocated by PyTorch, and 20.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.40 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 77.98 GiB memory in use. Of the allocated memory 57.12 GiB is allocated by PyTorch, and 20.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.39 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 77.98 GiB memory in use. Of the allocated memory 55.93 GiB is allocated by PyTorch, and 21.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 77.98 GiB memory in use. Of the allocated memory 56.13 GiB is allocated by PyTorch, and 21.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 820.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 58.79 GiB is allocated by PyTorch, and 19.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 3: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 3 has a total capacity of 79.11 GiB of which 446.94 MiB is free. Including non-PyTorch memory, this process has 78.66 GiB memory in use. Of the allocated memory 55.48 GiB is allocated by PyTorch, and 22.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 77.98 GiB memory in use. Of the allocated memory 55.17 GiB is allocated by PyTorch, and 22.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.39 GiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 56.43 GiB is allocated by PyTorch, and 21.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.46 GiB. GPU 1 has a total capacity of 79.11 GiB of which 168.94 MiB is free. Including non-PyTorch memory, this process has 78.94 GiB memory in use. Of the allocated memory 60.87 GiB is allocated by PyTorch, and 17.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 756.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 168.94 MiB is free. Including non-PyTorch memory, this process has 78.94 GiB memory in use. Of the allocated memory 54.34 GiB is allocated by PyTorch, and 23.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.47 GiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 61.43 GiB is allocated by PyTorch, and 16.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 748.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 168.94 MiB is free. Including non-PyTorch memory, this process has 78.94 GiB memory in use. Of the allocated memory 55.33 GiB is allocated by PyTorch, and 22.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 742.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 168.94 MiB is free. Including non-PyTorch memory, this process has 78.94 GiB memory in use. Of the allocated memory 55.22 GiB is allocated by PyTorch, and 23.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 58.92 GiB is allocated by PyTorch, and 19.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 168.94 MiB is free. Including non-PyTorch memory, this process has 78.94 GiB memory in use. Of the allocated memory 54.57 GiB is allocated by PyTorch, and 23.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.40 GiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 21.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 766.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 168.94 MiB is free. Including non-PyTorch memory, this process has 78.94 GiB memory in use. Of the allocated memory 54.84 GiB is allocated by PyTorch, and 23.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.39 GiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 56.76 GiB is allocated by PyTorch, and 21.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 742.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 168.94 MiB is free. Including non-PyTorch memory, this process has 78.94 GiB memory in use. Of the allocated memory 54.26 GiB is allocated by PyTorch, and 24.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.44 GiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 58.63 GiB is allocated by PyTorch, and 19.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 168.94 MiB is free. Including non-PyTorch memory, this process has 78.94 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 23.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 798.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 58.30 GiB is allocated by PyTorch, and 19.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 812.00 MiB. GPU 0 has a total capacity of 79.11 GiB of which 380.94 MiB is free. Including non-PyTorch memory, this process has 78.73 GiB memory in use. Of the allocated memory 58.94 GiB is allocated by PyTorch, and 19.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.40 GiB. GPU 0 has a total capacity of 79.11 GiB of which 1.26 GiB is free. Including non-PyTorch memory, this process has 77.84 GiB memory in use. Of the allocated memory 56.91 GiB is allocated by PyTorch, and 20.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 1 has a total capacity of 79.11 GiB of which 168.94 MiB is free. Including non-PyTorch memory, this process has 78.94 GiB memory in use. Of the allocated memory 55.29 GiB is allocated by PyTorch, and 22.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.40 GiB. GPU 0 has a total capacity of 79.11 GiB of which 1.26 GiB is free. Including non-PyTorch memory, this process has 77.84 GiB memory in use. Of the allocated memory 57.22 GiB is allocated by PyTorch, and 19.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 770.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 168.94 MiB is free. Including non-PyTorch memory, this process has 78.94 GiB memory in use. Of the allocated memory 55.27 GiB is allocated by PyTorch, and 23.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 754.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 168.94 MiB is free. Including non-PyTorch memory, this process has 78.94 GiB memory in use. Of the allocated memory 55.74 GiB is allocated by PyTorch, and 22.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 0: CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacity of 79.11 GiB of which 1.26 GiB is free. Including non-PyTorch memory, this process has 77.84 GiB memory in use. Of the allocated memory 58.03 GiB is allocated by PyTorch, and 19.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 168.94 MiB is free. Including non-PyTorch memory, this process has 78.94 GiB memory in use. Of the allocated memory 54.46 GiB is allocated by PyTorch, and 23.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1006.94 MiB is free. Including non-PyTorch memory, this process has 78.12 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 23.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1006.94 MiB is free. Including non-PyTorch memory, this process has 78.12 GiB memory in use. Of the allocated memory 54.53 GiB is allocated by PyTorch, and 22.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1006.94 MiB is free. Including non-PyTorch memory, this process has 78.12 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 23.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1006.94 MiB is free. Including non-PyTorch memory, this process has 78.12 GiB memory in use. Of the allocated memory 54.63 GiB is allocated by PyTorch, and 22.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 1 has a total capacity of 79.11 GiB of which 246.94 MiB is free. Including non-PyTorch memory, this process has 78.86 GiB memory in use. Of the allocated memory 54.79 GiB is allocated by PyTorch, and 23.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 752.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 246.94 MiB is free. Including non-PyTorch memory, this process has 78.86 GiB memory in use. Of the allocated memory 55.47 GiB is allocated by PyTorch, and 22.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 246.94 MiB is free. Including non-PyTorch memory, this process has 78.86 GiB memory in use. Of the allocated memory 54.04 GiB is allocated by PyTorch, and 24.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 246.94 MiB is free. Including non-PyTorch memory, this process has 78.86 GiB memory in use. Of the allocated memory 54.28 GiB is allocated by PyTorch, and 23.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 760.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 246.94 MiB is free. Including non-PyTorch memory, this process has 78.86 GiB memory in use. Of the allocated memory 55.18 GiB is allocated by PyTorch, and 23.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 246.94 MiB is free. Including non-PyTorch memory, this process has 78.86 GiB memory in use. Of the allocated memory 55.01 GiB is allocated by PyTorch, and 23.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 742.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 246.94 MiB is free. Including non-PyTorch memory, this process has 78.86 GiB memory in use. Of the allocated memory 55.00 GiB is allocated by PyTorch, and 23.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 752.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 246.94 MiB is free. Including non-PyTorch memory, this process has 78.86 GiB memory in use. Of the allocated memory 54.52 GiB is allocated by PyTorch, and 23.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 746.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 246.94 MiB is free. Including non-PyTorch memory, this process has 78.86 GiB memory in use. Of the allocated memory 55.27 GiB is allocated by PyTorch, and 22.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.37 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1006.94 MiB is free. Including non-PyTorch memory, this process has 78.12 GiB memory in use. Of the allocated memory 54.70 GiB is allocated by PyTorch, and 22.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 758.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 248.94 MiB is free. Including non-PyTorch memory, this process has 78.86 GiB memory in use. Of the allocated memory 54.97 GiB is allocated by PyTorch, and 23.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 740.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 248.94 MiB is free. Including non-PyTorch memory, this process has 78.86 GiB memory in use. Of the allocated memory 55.12 GiB is allocated by PyTorch, and 23.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 750.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 248.94 MiB is free. Including non-PyTorch memory, this process has 78.86 GiB memory in use. Of the allocated memory 55.65 GiB is allocated by PyTorch, and 22.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 248.94 MiB is free. Including non-PyTorch memory, this process has 78.86 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 23.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 776.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 426.94 MiB is free. Including non-PyTorch memory, this process has 78.68 GiB memory in use. Of the allocated memory 55.57 GiB is allocated by PyTorch, and 22.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.24 GiB is free. Including non-PyTorch memory, this process has 77.86 GiB memory in use. Of the allocated memory 54.35 GiB is allocated by PyTorch, and 22.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.24 GiB is free. Including non-PyTorch memory, this process has 77.86 GiB memory in use. Of the allocated memory 54.37 GiB is allocated by PyTorch, and 22.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 772.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 494.94 MiB is free. Including non-PyTorch memory, this process has 78.62 GiB memory in use. Of the allocated memory 56.60 GiB is allocated by PyTorch, and 21.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.30 GiB is free. Including non-PyTorch memory, this process has 77.80 GiB memory in use. Of the allocated memory 54.87 GiB is allocated by PyTorch, and 22.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.30 GiB is free. Including non-PyTorch memory, this process has 77.80 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 22.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.30 GiB is free. Including non-PyTorch memory, this process has 77.80 GiB memory in use. Of the allocated memory 54.23 GiB is allocated by PyTorch, and 22.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.30 GiB is free. Including non-PyTorch memory, this process has 77.80 GiB memory in use. Of the allocated memory 53.98 GiB is allocated by PyTorch, and 23.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.30 GiB is free. Including non-PyTorch memory, this process has 77.80 GiB memory in use. Of the allocated memory 54.39 GiB is allocated by PyTorch, and 22.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.30 GiB is free. Including non-PyTorch memory, this process has 77.80 GiB memory in use. Of the allocated memory 54.05 GiB is allocated by PyTorch, and 23.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.30 GiB is free. Including non-PyTorch memory, this process has 77.80 GiB memory in use. Of the allocated memory 54.24 GiB is allocated by PyTorch, and 22.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 766.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 568.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 55.52 GiB is allocated by PyTorch, and 22.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 568.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 53.83 GiB is allocated by PyTorch, and 24.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 760.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 568.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 54.68 GiB is allocated by PyTorch, and 23.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.38 GiB. GPU 1 has a total capacity of 79.11 GiB of which 568.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 55.78 GiB is allocated by PyTorch, and 22.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 748.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 568.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 55.39 GiB is allocated by PyTorch, and 22.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 740.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 568.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 54.32 GiB is allocated by PyTorch, and 23.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 568.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 54.59 GiB is allocated by PyTorch, and 23.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 568.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 54.60 GiB is allocated by PyTorch, and 23.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 752.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 568.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 55.02 GiB is allocated by PyTorch, and 22.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 568.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 54.46 GiB is allocated by PyTorch, and 23.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.31 GiB is free. Including non-PyTorch memory, this process has 77.79 GiB memory in use. Of the allocated memory 54.99 GiB is allocated by PyTorch, and 22.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 1.31 GiB is free. Including non-PyTorch memory, this process has 77.79 GiB memory in use. Of the allocated memory 54.69 GiB is allocated by PyTorch, and 22.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 608.94 MiB is free. Including non-PyTorch memory, this process has 78.51 GiB memory in use. Of the allocated memory 54.22 GiB is allocated by PyTorch, and 23.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 764.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 576.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 53.97 GiB is allocated by PyTorch, and 23.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 742.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 576.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 54.29 GiB is allocated by PyTorch, and 23.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 576.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 54.29 GiB is allocated by PyTorch, and 23.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 748.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 576.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 55.12 GiB is allocated by PyTorch, and 22.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 744.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 576.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 53.80 GiB is allocated by PyTorch, and 24.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 576.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 54.99 GiB is allocated by PyTorch, and 22.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 576.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 54.92 GiB is allocated by PyTorch, and 22.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 746.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 576.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 54.52 GiB is allocated by PyTorch, and 23.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 576.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 54.40 GiB is allocated by PyTorch, and 23.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 576.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 54.15 GiB is allocated by PyTorch, and 23.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.36 GiB. GPU 1 has a total capacity of 79.11 GiB of which 576.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 54.60 GiB is allocated by PyTorch, and 23.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 744.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 576.94 MiB is free. Including non-PyTorch memory, this process has 78.54 GiB memory in use. Of the allocated memory 53.93 GiB is allocated by PyTorch, and 23.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 790.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 742.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 54.48 GiB is allocated by PyTorch, and 23.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 748.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 742.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 53.57 GiB is allocated by PyTorch, and 24.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 742.00 MiB. GPU 1 has a total capacity of 79.11 GiB of which 742.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 54.46 GiB is allocated by PyTorch, and 23.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
GPU 1: CUDA out of memory. Tried to allocate 1.35 GiB. GPU 1 has a total capacity of 79.11 GiB of which 742.94 MiB is free. Including non-PyTorch memory, this process has 78.38 GiB memory in use. Of the allocated memory 54.43 GiB is allocated by PyTorch, and 23.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
